# 2.0.0 Pre-Alpha!

Recently, a realization that most Reddit pages you can add .json (before GET requests) and get the JSON data used in the page creation waved over me. Instead of beating a dead horse, I went on to recode it, but better. Fixing many of the issues I have, that some people on discord pointed out (if you wish to be named, just ask.)

### Changelog 2.0.0 Pre-Alpha:
+ 'Added' graphical interface, much more friendly for anyone to use.
+ Cleaner user feedback, due to the advantage of a UI.
+ Cleaner code, better practices (furthering my understanding of J.S. currently).
+ Choose how many pages/users to fetch.

#### To Do:
+ Scrape for user data.
+ Save all data to a file.
+ Add tools to analyse data (this is really long overdue now isn't it).
+ Finish up pre-alpha.
+ And release with files included for the impenitent (Right now it isn't packed up).

## Usage:
  ###First off, you must clone/download it..
  ##### Windows (With git installed)
  `> git clone https://github.com/SlicesOfPi/reddituserinfoscraper.git` (or just download the .ZIP & extract.)
  ##### Linux/Mac (with git installed)
  `$ git clone https://github.com/SlicesOfPi/reddituserinfoscraper.git` (or just download the .ZIP & extract.)
  ### Further, download NW.js.
  `https://nwjs.io` Download the suitable executable.
  ### Install Dependencies
  `cd C:\Path\To\reddituserinfoscraper` or `$ cd /path/to/reddituserinfoscraper`
  `npm install`
  ### Then, launch (still in ruis dir)
  ##### Windows
  `C:\Path\To\Your\Nw.js\Install\nw.exe .`
  ##### Linux/Mac
  `/Path/To/NWJS/nw .`
